{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3cf3b7",
   "metadata": {},
   "source": [
    "# Low-VA Simple Models- Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2726de0",
   "metadata": {},
   "source": [
    "Hyperparameter tuning on all models, including the number of units for the dense layer, the dropout rate for the dropout layers, and the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a847fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change your dependencies as you see fit\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import h5py \n",
    "import random \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb21779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
      "and then re-execute this cell.\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe06930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 31.6 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336073",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Loading the tokens (CUI's extracted from CLAMP) as one-hot embeddings (for both positive and negative terms). We have ignored the named entities that do not have a CUI mapped to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9dc20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clamp_output_df = pd.read_csv('gs://stanfordoptimagroup/STRIDE/lowva/clamp_output_postprocessing.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68c87aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading structured data\n"
     ]
    }
   ],
   "source": [
    "# code to load the pre-trained embeddings and dataset\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "csv.field_size_limit(1310720);\n",
    "\n",
    "print('\\nloading structured data')\n",
    "with open('../lowva-structured-02.csv', 'r') as f:\n",
    "    r = csv.reader(f)\n",
    "    i = 0\n",
    "    structuredDict = {}\n",
    "    outputDict = {}\n",
    "    for row in r:\n",
    "        i += 1\n",
    "        if i == 1:\n",
    "            continue\n",
    "        else:\n",
    "            key = row[0].strip()\n",
    "            values = np.array([float(i) for i in row[2:] if isfloat(i)])\n",
    "            structuredDict[key] = values\n",
    "            outputDict[key]= np.array([int(row[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098f7f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating tokenDict\n",
      "------------------------------------ Token Dataframe- list of all CUIs ------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>CUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1790</td>\n",
       "      <td>[C0154863p, C0242383p, C0086543p, C0586742p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2262</td>\n",
       "      <td>[C0030193p, C0022107p, C0332575p, C0039409p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2736</td>\n",
       "      <td>[C0154863p, C0743690p, C0043253p, C3665347p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2920</td>\n",
       "      <td>[C0700325p, C3234800p, C1721374p, C0007389p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3178</td>\n",
       "      <td>[C0024437p, C0593887p, C0017601p, C0085096p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>3840336</td>\n",
       "      <td>[C0201925p, C0220825p, C0749189p, C2126073p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>3840713</td>\n",
       "      <td>[C0220825p, C0582103p, C0008809p, C2064449p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>3840904</td>\n",
       "      <td>[C0344232p, C2126074p, C4554308p, C0012569p, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>3840966</td>\n",
       "      <td>[C0944554p, C0344232p, C0700135p, C0016242n, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>3843115</td>\n",
       "      <td>[C0348542p, C0239116p, C0543467p, C0151827n, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4393 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PID                                                CUI\n",
       "0        1790  [C0154863p, C0242383p, C0086543p, C0586742p, C...\n",
       "1        2262  [C0030193p, C0022107p, C0332575p, C0039409p, C...\n",
       "2        2736  [C0154863p, C0743690p, C0043253p, C3665347p, C...\n",
       "3        2920  [C0700325p, C3234800p, C1721374p, C0007389p, C...\n",
       "4        3178  [C0024437p, C0593887p, C0017601p, C0085096p, C...\n",
       "...       ...                                                ...\n",
       "4388  3840336  [C0201925p, C0220825p, C0749189p, C2126073p, C...\n",
       "4389  3840713  [C0220825p, C0582103p, C0008809p, C2064449p, C...\n",
       "4390  3840904  [C0344232p, C2126074p, C4554308p, C0012569p, C...\n",
       "4391  3840966  [C0944554p, C0344232p, C0700135p, C0016242n, C...\n",
       "4392  3843115  [C0348542p, C0239116p, C0543467p, C0151827n, C...\n",
       "\n",
       "[4393 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ TokensArray- one hot encoding------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C0000294p</th>\n",
       "      <th>C0000578n</th>\n",
       "      <th>C0000618p</th>\n",
       "      <th>C0000729p</th>\n",
       "      <th>C0000734n</th>\n",
       "      <th>C0000735p</th>\n",
       "      <th>C0000737n</th>\n",
       "      <th>C0000737p</th>\n",
       "      <th>C0000768n</th>\n",
       "      <th>C0000768p</th>\n",
       "      <th>...</th>\n",
       "      <th>C4750866p</th>\n",
       "      <th>C4751158p</th>\n",
       "      <th>C4751179p</th>\n",
       "      <th>C4751436p</th>\n",
       "      <th>C4758057p</th>\n",
       "      <th>C4759290p</th>\n",
       "      <th>C4759301p</th>\n",
       "      <th>C4759475p</th>\n",
       "      <th>C4759549n</th>\n",
       "      <th>C4759549p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4393 rows × 22164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      C0000294p  C0000578n  C0000618p  C0000729p  C0000734n  C0000735p  \\\n",
       "0             0          0          0          0          0          0   \n",
       "1             0          0          0          0          0          0   \n",
       "2             0          0          0          0          0          0   \n",
       "3             0          0          0          0          0          0   \n",
       "4             0          0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4388          0          0          0          0          0          0   \n",
       "4389          0          0          0          0          0          0   \n",
       "4390          0          0          0          0          0          0   \n",
       "4391          0          0          0          0          0          0   \n",
       "4392          0          0          0          0          0          0   \n",
       "\n",
       "      C0000737n  C0000737p  C0000768n  C0000768p  ...  C4750866p  C4751158p  \\\n",
       "0             0          0          0          0  ...          0          0   \n",
       "1             0          0          0          0  ...          0          0   \n",
       "2             0          0          0          0  ...          0          0   \n",
       "3             0          0          0          0  ...          0          0   \n",
       "4             0          0          0          0  ...          0          0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "4388          0          0          0          0  ...          0          0   \n",
       "4389          0          0          0          0  ...          0          0   \n",
       "4390          0          0          0          0  ...          0          0   \n",
       "4391          0          0          0          0  ...          0          0   \n",
       "4392          0          0          0          0  ...          0          0   \n",
       "\n",
       "      C4751179p  C4751436p  C4758057p  C4759290p  C4759301p  C4759475p  \\\n",
       "0             0          0          0          0          0          0   \n",
       "1             0          0          0          0          0          0   \n",
       "2             0          0          0          0          0          0   \n",
       "3             0          0          0          0          0          0   \n",
       "4             0          0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4388          0          0          0          0          0          0   \n",
       "4389          0          0          0          0          0          0   \n",
       "4390          0          0          0          0          0          0   \n",
       "4391          0          0          0          0          0          0   \n",
       "4392          0          0          0          0          0          0   \n",
       "\n",
       "      C4759549n  C4759549p  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "...         ...        ...  \n",
       "4388          0          0  \n",
       "4389          0          0  \n",
       "4390          0          0  \n",
       "4391          0          0  \n",
       "4392          0          0  \n",
       "\n",
       "[4393 rows x 22164 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\nCreating tokenDict')\n",
    "tokenDict=OrderedDict() #to ensure that the dictionary will maintain an order\n",
    "\n",
    "def check_negation(row):\n",
    "    if(row['Assertion'] == 'present'):\n",
    "        return row['CUI_clean'] + 'p'\n",
    "    else:\n",
    "        return row['CUI_clean'] + 'n'\n",
    "\n",
    "for index, row in clamp_output_df.iterrows():\n",
    "    if (str(row['PID']) in structuredDict): #make sure only including ones that have output results\n",
    "        if (isinstance(row['CUI_clean'], str)):\n",
    "            key = str(row['PID'])\n",
    "            if (key in tokenDict):\n",
    "                oldValue = tokenDict[key]\n",
    "                oldValue.append(check_negation(row))\n",
    "                tokenDict[key] = oldValue\n",
    "            else: \n",
    "                tokenDict[key] = [check_negation(row)]\n",
    "token_df = pd.DataFrame(list(tokenDict.items()),columns = ['PID','CUI']) \n",
    "\n",
    "print('------------------------------------ Token Dataframe- list of all CUIs ------------------------------------')\n",
    "display(token_df)\n",
    "\n",
    "# One hot encoding\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "\n",
    "tokensOneHot = pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(token_df.pop('CUI')),\n",
    "                index=token_df.index,\n",
    "                columns=mlb.classes_)\n",
    "print('------------------------------------ TokensArray- one hot encoding------------------------------------')\n",
    "display(tokensOneHot)\n",
    "\n",
    "#Variance Filtering: filtering out near zero variance features from data frame while preserving names\n",
    "selector = VarianceThreshold(.99 * (1 - .99))\n",
    "tokensArray = selector.fit_transform(tokensOneHot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041c0c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and joining with unstructured data\n",
      "(4393, 1078) (4393, 556) (4393, 1)\n"
     ]
    }
   ],
   "source": [
    "print('loading and joining with unstructured data')\n",
    "\n",
    "outputArray = []\n",
    "structuredArray = []\n",
    "for key in tokenDict: #to make sure that it's the same order as the tokenArray\n",
    "    structvalues = structuredDict[key]\n",
    "    output = outputDict[key]\n",
    "    \n",
    "    structuredArray.append(structvalues)\n",
    "    outputArray.append(output)\n",
    "\n",
    "outputArray = np.array(outputArray)\n",
    "structuredArray = np.array(structuredArray)\n",
    "tokenArray = tokensArray.toarray() # after variance filtering, need to convert from sparse array to dense\n",
    "\n",
    "print(tokenArray.shape, structuredArray.shape, outputArray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c7dacc",
   "metadata": {},
   "source": [
    "# Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8531fe",
   "metadata": {},
   "source": [
    "## Model A) Structured Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1125444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 01:23:39.851191: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices(structuredArray)\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790a3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    dense1_hp_units = hp.Int('dense_1', min_value=32, max_value=1024, step=32)\n",
    "    dense2_hp_units = hp.Int('dense_2', min_value=32, max_value=1024, step=32)\n",
    "    dropout1_hp_units = hp.Float('dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    input2 = tf.keras.Input(shape=(structuredArray.shape[1],))\n",
    "    sl = tf.keras.layers.Dense(units = dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input2)\n",
    "    sl = tf.keras.layers.Dropout(rate = dropout1_hp_units)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(sl)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input2, outputs = output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3353a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.7133333086967468\n",
      "\n",
      "Best val_accuracy So Far: 0.7766666412353516\n",
      "Total elapsed time: 00h 14m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "First densely-connected layer: 480\n",
      "Dropout layer: 0.5\n",
      "Second densely-connected layer: 608\n",
      "Optimal learning rate: 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct00',\n",
    "                     overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "First densely-connected layer: {best_hps.get('dense_1')}\n",
    "Dropout layer: {best_hps.get('dropout_1')}\n",
    "Second densely-connected layer: {best_hps.get('dense_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46131433",
   "metadata": {},
   "source": [
    "Best results: \\\n",
    "First densely-connected layer: 480 \\\n",
    "Dropout layer: 0.5 \\\n",
    "Second densely-connected layer: 608 \\\n",
    "Optimal learning rate: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b615aa",
   "metadata": {},
   "source": [
    "## (Model C) CUI One-Hot Encoding Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "912a7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices(tokenArray)\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90d20b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    dense1_hp_units = hp.Int('dense_1', min_value=32, max_value=1024, step=32)\n",
    "    dense2_hp_units = hp.Int('dense_2', min_value=32, max_value=1024, step=32)\n",
    "    dropout1_hp_units = hp.Float('dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    input2 = tf.keras.Input(shape=(tokenArray.shape[1],))\n",
    "    sl = tf.keras.layers.Dense(units = dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input2)\n",
    "    sl = tf.keras.layers.Dropout(rate = dropout1_hp_units)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(sl)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input2, outputs = output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c38be27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 12s]\n",
      "val_accuracy: 0.6366666555404663\n",
      "\n",
      "Best val_accuracy So Far: 0.6499999761581421\n",
      "Total elapsed time: 00h 10m 50s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "First densely-connected layer: 608\n",
      "Dropout layer: 0.4\n",
      "Second densely-connected layer: 608\n",
      "Optimal learning rate: 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct01',\n",
    "                     overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "First densely-connected layer: {best_hps.get('dense_1')}\n",
    "Dropout layer: {best_hps.get('dropout_1')}\n",
    "Second densely-connected layer: {best_hps.get('dense_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54df5ad",
   "metadata": {},
   "source": [
    "Best results:\\\n",
    "First densely-connected layer: 608\\\n",
    "Dropout layer: 0.4\\\n",
    "Second densely-connected layer: 608\\\n",
    "Optimal learning rate: 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad45ff",
   "metadata": {},
   "source": [
    "## (Model F) Structured and CUI one-hot combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6abfa5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices(np.hstack((tokenArray, structuredArray)))\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4cfa78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    dense1_hp_units = hp.Int('dense_1', min_value=32, max_value=1024, step=32)\n",
    "    dense2_hp_units = hp.Int('dense_2', min_value=32, max_value=1024, step=32)\n",
    "    dropout1_hp_units = hp.Float('dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    input2 = tf.keras.Input(shape=((tokenArray.shape[1]+structuredArray.shape[1]),))\n",
    "    sl = tf.keras.layers.Dense(units = dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input2)\n",
    "    sl = tf.keras.layers.Dropout(rate = dropout1_hp_units)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(sl)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input2, outputs = output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92ef77da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 18s]\n",
      "val_accuracy: 0.7833333611488342\n",
      "\n",
      "Best val_accuracy So Far: 0.7900000214576721\n",
      "Total elapsed time: 00h 12m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "First densely-connected layer: 704\n",
      "Dropout layer: 0.5\n",
      "Second densely-connected layer: 448\n",
      "Optimal learning rate: 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct02',\n",
    "                     overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "First densely-connected layer: {best_hps.get('dense_1')}\n",
    "Dropout layer: {best_hps.get('dropout_1')}\n",
    "Second densely-connected layer: {best_hps.get('dense_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60301169",
   "metadata": {},
   "source": [
    "Best results:\\\n",
    "First densely-connected layer: 704\\\n",
    "Dropout layer: 0.5\\\n",
    "Second densely-connected layer: 448\\\n",
    "Optimal learning rate: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbbed49",
   "metadata": {},
   "source": [
    "# Word embedding with pretrained cui2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50365c",
   "metadata": {},
   "source": [
    "### Loading CUI's to create cui2vec embeddings (converting to \"sentence of cui's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463b38ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.00990000000000001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C0000737n</th>\n",
       "      <th>C0000975p</th>\n",
       "      <th>C0001367p</th>\n",
       "      <th>C0001425p</th>\n",
       "      <th>C0001927p</th>\n",
       "      <th>C0002418p</th>\n",
       "      <th>C0002600p</th>\n",
       "      <th>C0002645p</th>\n",
       "      <th>C0002871n</th>\n",
       "      <th>C0002871p</th>\n",
       "      <th>...</th>\n",
       "      <th>C4699683p</th>\n",
       "      <th>C4699689p</th>\n",
       "      <th>C4700122p</th>\n",
       "      <th>C4700200n</th>\n",
       "      <th>C4708770p</th>\n",
       "      <th>C4718671n</th>\n",
       "      <th>C4718671p</th>\n",
       "      <th>C4738298p</th>\n",
       "      <th>C4745561p</th>\n",
       "      <th>C4748411p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4393 rows × 1078 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      C0000737n  C0000975p  C0001367p  C0001425p  C0001927p  C0002418p  \\\n",
       "0             0          0          0          0          0          0   \n",
       "1             0          0          0          0          0          0   \n",
       "2             0          0          0          0          0          0   \n",
       "3             0          0          0          0          0          0   \n",
       "4             0          0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4388          0          0          0          0          0          0   \n",
       "4389          0          0          0          0          0          0   \n",
       "4390          0          0          0          0          0          0   \n",
       "4391          0          1          0          0          0          0   \n",
       "4392          0          0          0          0          1          0   \n",
       "\n",
       "      C0002600p  C0002645p  C0002871n  C0002871p  ...  C4699683p  C4699689p  \\\n",
       "0             0          0          0          0  ...          0          0   \n",
       "1             0          0          0          0  ...          0          0   \n",
       "2             0          0          0          0  ...          0          0   \n",
       "3             0          0          0          0  ...          0          0   \n",
       "4             0          0          0          0  ...          1          0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "4388          0          0          0          1  ...          0          0   \n",
       "4389          0          0          0          0  ...          0          0   \n",
       "4390          0          0          0          0  ...          0          0   \n",
       "4391          0          0          0          0  ...          0          0   \n",
       "4392          0          0          0          1  ...          0          0   \n",
       "\n",
       "      C4700122p  C4700200n  C4708770p  C4718671n  C4718671p  C4738298p  \\\n",
       "0             0          0          0          1          0          0   \n",
       "1             0          0          0          0          0          0   \n",
       "2             0          0          0          0          1          0   \n",
       "3             0          0          0          0          0          0   \n",
       "4             0          0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4388          0          0          0          0          0          0   \n",
       "4389          0          0          0          0          1          0   \n",
       "4390          0          0          0          0          0          0   \n",
       "4391          0          0          0          0          0          0   \n",
       "4392          0          0          0          0          0          0   \n",
       "\n",
       "      C4745561p  C4748411p  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "...         ...        ...  \n",
       "4388          0          0  \n",
       "4389          0          0  \n",
       "4390          0          0  \n",
       "4391          0          1  \n",
       "4392          0          0  \n",
       "\n",
       "[4393 rows x 1078 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variance Threshold for word embedding (cui2vec)\n",
    "selector = VarianceThreshold(.99 * (1 - .99));\n",
    "selector.fit(tokensOneHot);\n",
    "tokenArray_df = tokensOneHot[tokensOneHot.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "display(tokenArray_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdec424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4392\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "cuiDict={}\n",
    "\n",
    "# Returning only positive cui's\n",
    "def adapt_cui(cui):\n",
    "    if 'n' in cui:\n",
    "        return ' '\n",
    "    if 'p' in cui:\n",
    "        return cui[0:len(cui)-1]\n",
    "\n",
    "# creating a vocab out of the cui's (creating a sentence from the extracted name-entities)\n",
    "pid_list_tokenDict = [*tokenDict]\n",
    "\n",
    "for index, row in tokenArray_df.iterrows(): #tokenArray_df is after variance filtering\n",
    "    for column in tokenArray_df: #iterating through all the columns to get the cui's\n",
    "        if (row[column] == 1): #only if patient has the cui\n",
    "            value = adapt_cui(column)\n",
    "            vocabulary.add(value)\n",
    "            key = pid_list_tokenDict[index]\n",
    "            if (key in cuiDict):\n",
    "                oldValue = cuiDict[key]\n",
    "                newValue = oldValue + ' ' + value\n",
    "                cuiDict[key] = newValue\n",
    "            else: \n",
    "                cuiDict[key] = value\n",
    "\n",
    "print(len(cuiDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae55b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cui2vec vectors\n",
      "Loaded 109053 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Loading pertrained cui2vec embedding\n",
    "\n",
    "print('loading cui2vec vectors')\n",
    "cui2vec_df = pd.read_csv('gs://stanfordoptimagroup/STRIDE/lowva/cui2vec_pretrained.csv', delimiter = \",\")\n",
    "cui2vec_df.rename(columns={'Unnamed: 0':'CUI'}, inplace=True)\n",
    "cui2vec_map = cui2vec_df.set_index('CUI').T.to_dict('list') # Create dictionary from df\n",
    "\n",
    "print('Loaded %s word vectors.' % len(cui2vec_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7aaaa",
   "metadata": {},
   "source": [
    "### Loading pubmed word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f07ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrinsicdata_df = pd.read_csv('../lowva-extrinsicdata.csv', delimiter = \",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02083937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Pubmed Size 55940\n",
      "Creating wordDict\n",
      "Max Length of words in patient: 1000\n",
      "loading Pubmed EMR vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 04:25:57.985551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55940, 300)\n"
     ]
    }
   ],
   "source": [
    "vocabulary_pubmed = []\n",
    "with open('../pubmed_cbow_vocabulary.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        vocabulary_pubmed.append(row.strip())\n",
    "\n",
    "# Create Tokenizer\n",
    "vocabulary_pubmed_size = len(vocabulary_pubmed) + 2\n",
    "print('Vocab Pubmed Size', vocabulary_pubmed_size)\n",
    "tokenizer_pubmed = tfds.deprecated.text.Tokenizer()\n",
    "\n",
    "width = 1000\n",
    "pubmed_embedding_dimension = 300\n",
    "pubmed_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_pubmed, tokenizer = tokenizer_pubmed)\n",
    "\n",
    "print('Creating wordDict')\n",
    "wordDict = {}\n",
    "\n",
    "for index, row in extrinsicdata_df.iterrows():\n",
    "    if (str(row[0]) in cuiDict): #make sure only including ones that have output results\n",
    "        key = str(row[0])\n",
    "        words = pubmed_encoder.encode(row[2])\n",
    "        words = words[0:width]\n",
    "        if len(words) < width:\n",
    "            words = words + [0 for i in range(width-len(words))] \n",
    "        wordDict[key] = words\n",
    "\n",
    "print('Max Length of words in patient:', width)\n",
    "\n",
    "print('loading Pubmed EMR vectors')\n",
    "model = tf.keras.models.load_model('../pubmed_cbow_embeddings.h5')\n",
    "pubmed_embedding_matrix = np.zeros((vocabulary_pubmed_size, pubmed_embedding_dimension))\n",
    "pubmed_e = model.layers[1]\n",
    "pubmed_embedding_matrix = pubmed_e.get_weights()[0]\n",
    "print(pubmed_embedding_matrix.shape)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c22944",
   "metadata": {},
   "source": [
    "### Creating inputs (structuredArray, outputArray, wordArray, padded_cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "081d91e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4392, 556) (4392, 1) 4392 (4392, 1000)\n"
     ]
    }
   ],
   "source": [
    "# need to rerun because we are removing terms that are negative (might affect patient count)\n",
    "outputArray = []\n",
    "structuredArray = []\n",
    "cuiArray = []\n",
    "wordArray = []\n",
    "\n",
    "for key in wordDict: #to make sure that everything is same order\n",
    "    structvalues = structuredDict[key]\n",
    "    output = outputDict[key]\n",
    "    cui = cuiDict[key]\n",
    "    word = wordDict[key] #TOGGLE\n",
    "    \n",
    "    structuredArray.append(structvalues)\n",
    "    outputArray.append(output)\n",
    "    cuiArray.append(cui)\n",
    "    wordArray.append(word) #TOGGLE\n",
    "\n",
    "outputArray = np.array(outputArray)\n",
    "structuredArray = np.array(structuredArray)\n",
    "wordArray = np.array(wordArray)\n",
    "\n",
    "print(structuredArray.shape, outputArray.shape, len(cuiArray), wordArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff38fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size 816\n",
      "[[ 61   4   9 ...   0   0   0]\n",
      " [  8 357  15 ...   0   0   0]\n",
      " [ 98  18   6 ...   0   0   0]\n",
      " ...\n",
      " [  8 331 249 ...   0   0   0]\n",
      " [  8  61   4 ...   0   0   0]\n",
      " [280 505 807 ...   0   0   0]]\n",
      "(4392, 239)\n",
      "Max Length of CUI in patient: 239\n"
     ]
    }
   ],
   "source": [
    "# Create Tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(cuiArray)\n",
    "vocabulary_size = len(vocabulary) + 1\n",
    "print('Vocab Size', vocabulary_size)\n",
    "\n",
    "# Integer encode the documents\n",
    "encoded_cui = tokenizer.texts_to_sequences(cuiArray)\n",
    "# print(encoded_cui)\n",
    "\n",
    "# Pad documents to max length\n",
    "max_length = max(map(len, encoded_cui)) #getting max length of the number of cui's per patient\n",
    "\n",
    "# max_length = 4000 #arbitrary number set to decrease the size (only 3 patients have more than 4000 cui's)\n",
    "padded_cui = tf.keras.preprocessing.sequence.pad_sequences(encoded_cui, maxlen = max_length, padding='post')\n",
    "print(padded_cui)\n",
    "print(padded_cui.shape)\n",
    "print('Max Length of CUI in patient:', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7358916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 109053 word vectors.\n",
      "(816, 500)\n"
     ]
    }
   ],
   "source": [
    "# Create cui2vec embedding\n",
    "\n",
    "embedding_dimension = 500 #number pulled from the cui2vec pretrained word embeddings\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dimension))\n",
    "\n",
    "print('Loaded %s word vectors.' % len(cui2vec_map))\n",
    "\n",
    "# Creating a weight matrix for words in the training docs\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = cui2vec_map.get(word.upper()) #need to convert to upper case b/c tokenizer makes all lowercase\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1f690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del clamp_output_df\n",
    "del token_df\n",
    "del tokenArray_df\n",
    "del cui2vec_df\n",
    "del extrinsicdata_df\n",
    "del structuredDict\n",
    "del outputDict\n",
    "del tokenDict\n",
    "del pid_list_tokenDict\n",
    "del cuiDict\n",
    "del wordDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1085f6",
   "metadata": {},
   "source": [
    "## (Model D) Cui2vec text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3a30e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices(padded_cui)\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)\n",
    "max_length = max(map(len, encoded_cui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5417b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    dense1_hp_units = hp.Int('dense_1', min_value=32, max_value=512, step=32)\n",
    "    dense2_hp_units = hp.Int('dense_2', min_value=32, max_value=512, step=32)\n",
    "    dropout1_hp_units = hp.Float('dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    input1 = tf.keras.Input(shape=(max_length,))\n",
    "    nl = tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), input_length = max_length, trainable=False)(input1)\n",
    "    nl = tf.keras.layers.Flatten()(nl)\n",
    "    nl = tf.keras.layers.Dense(units = dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "    nl = tf.keras.layers.Dropout(rate = dropout1_hp_units)(nl)\n",
    "    nl = tf.keras.layers.Dense(units = dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(nl)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = input1, outputs = output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bf64a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperparameter_tuning/struct03/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hyperparameter_tuning/struct03/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "First densely-connected layer: 224\n",
      "Dropout layer: 0.30000000000000004\n",
      "Second densely-connected layer: 128\n",
      "Optimal learning rate: 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct03');\n",
    "#                      overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "First densely-connected layer: {best_hps.get('dense_1')}\n",
    "Dropout layer: {best_hps.get('dropout_1')}\n",
    "Second densely-connected layer: {best_hps.get('dense_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21424dd0",
   "metadata": {},
   "source": [
    "Best results:\\\n",
    "First densely-connected layer: 224\\\n",
    "Dropout layer: 0.30000000000000004\\\n",
    "Second densely-connected layer: 128\\\n",
    "Optimal learning rate: 0.0001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eca59",
   "metadata": {},
   "source": [
    "# (3.2) Pubmed word embedding + structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices((wordArray, structuredArray))\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)\n",
    "max_length = max(map(len, encoded_cui))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ff911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    pubmed_dense1_hp_units = hp.Int('pubmed_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    pubmed_dense2_hp_units = hp.Int('pubmed_dense_2', min_value=32, max_value=1024, step=32)\n",
    "    pubmed_dropout1_hp_units = hp.Float('pubmed_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    struct_dense1_hp_units = hp.Int('struct_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    struct_dense2_hp_units = hp.Int('struct_dense_2', min_value=32, max_value=1024, step=32)\n",
    "    struct_dropout1_hp_units = hp.Float('struct_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    combo_dense1_hp_units = hp.Int('combo_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    \n",
    "    input2 = tf.keras.Input(shape=(width,))\n",
    "    nl2 = tf.keras.layers.Embedding(vocabulary_pubmed_size, pubmed_embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(pubmed_embedding_matrix), input_length = width, trainable=False)(input2)\n",
    "    nl2 = tf.keras.layers.Flatten()(nl2)\n",
    "    nl2 = tf.keras.layers.Dense(units = pubmed_dense_1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl2)\n",
    "    nl2 = tf.keras.layers.Dropout(rate = pubmed_dropout_1)(nl2)\n",
    "    nl2 = tf.keras.layers.Dense(units = pubmed_dense_2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl2)\n",
    "\n",
    "    input3 = tf.keras.Input(shape=(structuredArray.shape[1],))\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense_1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input3)\n",
    "    sl = tf.keras.layers.Dropout(rate = struct_dropout_1)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense_2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "\n",
    "    combo = tf.keras.layers.Concatenate()([nl2, sl])\n",
    "    combo = tf.keras.layers.Dense(units = combo_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(combo)\n",
    "    nl = combo\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(nl)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = (input2, input3), outputs = output)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct032',\n",
    "                     overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "Pubmed- first densely-connected layer: {best_hps.get('pubmed_dense_1')}\n",
    "Pubmed- dropout layer: {best_hps.get('pubmed_dropout_1')}\n",
    "Pubmed- second densely-connected layer: {best_hps.get('pubmed_dense_2')}\n",
    "Struct- first densely-connected layer: {best_hps.get('struct_dense_1')}\n",
    "Struct- dropout layer: {best_hps.get('struct_dropout_1')}\n",
    "Struct- second densely-connected layer: {best_hps.get('struct_dense_2')}\n",
    "Combo- densely-connected layer: {best_hps.get('combo_dense_1')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81b1a8",
   "metadata": {},
   "source": [
    "# (Model E) Structured + CNN word embedding Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675c2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "total_input = tf.data.Dataset.from_tensor_slices((padded_cui, structuredArray))\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "020264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    cui2vec_dense1_hp_units = hp.Int('cui2vec_dense_1', min_value=32, max_value=512, step=32)\n",
    "    cui2vec_dense2_hp_units = hp.Int('cui2vec_dense_2', min_value=32, max_value=512, step=32)\n",
    "    cui2vec_dropout1_hp_units = hp.Float('cui2vec_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    struct_dense1_hp_units = hp.Int('struct_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    struct_dense2_hp_units = hp.Int('struct_dense_2', min_value=32, max_value=1024, step=32)\n",
    "    struct_dropout1_hp_units = hp.Float('struct_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    combo_dense1_hp_units = hp.Int('combo_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    \n",
    "    input1 = tf.keras.Input(shape=(max_length,))\n",
    "    nl = tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), input_length = max_length, trainable=False)(input1)\n",
    "    nl = tf.keras.layers.Flatten()(nl)\n",
    "    nl = tf.keras.layers.Dense(units = cui2vec_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "    nl = tf.keras.layers.Dropout(rate = cui2vec_dropout1_hp_units)(nl)\n",
    "    nl = tf.keras.layers.Dense(units = cui2vec_dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "\n",
    "    input2 = tf.keras.Input(shape=(structuredArray.shape[1],))\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input2)\n",
    "    sl = tf.keras.layers.Dropout(rate = struct_dropout1_hp_units)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "\n",
    "    combo = tf.keras.layers.Concatenate()([nl, sl])\n",
    "    combo = tf.keras.layers.Dense(units = combo_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(combo)\n",
    "    nl = combo\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(nl)\n",
    "\n",
    "    model = tf.keras.Model(inputs = (input1, input2), outputs = output)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f218d6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperparameter_tuning/struct035/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hyperparameter_tuning/struct035/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "Cui2vec- first densely-connected layer: 128\n",
      "Cui2vec- dropout layer: 0.6000000000000001\n",
      "Cui2vec- second densely-connected layer: 320\n",
      "Struct- first densely-connected layer: 416\n",
      "Struct- dropout layer: 0.5\n",
      "Struct- second densely-connected layer: 480\n",
      "Combo- densely-connected layer: 448\n",
      "Optimal learning rate: 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct035')\n",
    "#                      overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "Cui2vec- first densely-connected layer: {best_hps.get('cui2vec_dense_1')}\n",
    "Cui2vec- dropout layer: {best_hps.get('cui2vec_dropout_1')}\n",
    "Cui2vec- second densely-connected layer: {best_hps.get('cui2vec_dense_2')}\n",
    "Struct- first densely-connected layer: {best_hps.get('struct_dense_1')}\n",
    "Struct- dropout layer: {best_hps.get('struct_dropout_1')}\n",
    "Struct- second densely-connected layer: {best_hps.get('struct_dense_2')}\n",
    "Combo- densely-connected layer: {best_hps.get('combo_dense_1')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6ced6",
   "metadata": {},
   "source": [
    "Best results:\\\n",
    "Cui2vec- first densely-connected layer: 128\\\n",
    "Cui2vec- dropout layer: 0.6000000000000001\\\n",
    "Cui2vec- second densely-connected layer: 320\\\n",
    "Struct- first densely-connected layer: 416\\\n",
    "Struct- dropout layer: 0.5\\\n",
    "Struct- second densely-connected layer: 480\\\n",
    "Combo- densely-connected layer: 448\\\n",
    "Optimal learning rate: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73223c4a",
   "metadata": {},
   "source": [
    "# (Model H) Structured and cui2vec text model and fully connected word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d93f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_input = tf.data.Dataset.from_tensor_slices(structuredArray)\n",
    "#total_input = tf.data.Dataset.from_tensor_slices(tokenArray)\n",
    "total_input = tf.data.Dataset.from_tensor_slices((padded_cui, wordArray, structuredArray))\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8631623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    cui2vec_dense1_hp_units = hp.Int('cui2vec_dense_1', min_value=32, max_value=512, step=32)\n",
    "    cui2vec_dense2_hp_units = hp.Int('cui2vec_dense_2', min_value=32, max_value=512, step=32)\n",
    "    cui2vec_dropout1_hp_units = hp.Float('cui2vec_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    pubmed_dense1_hp_units = hp.Int('pubmed_dense_1', min_value=32, max_value=512, step=32)\n",
    "    pubmed_convo_hp_units = hp.Int('pubmed_convo_size', min_value=32, max_value=512, step=32)\n",
    "    pubmed_dropout1_hp_units = hp.Float('pubmed_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    pubmed_dense3_hp_units = hp.Int('pubmed_dense_3', min_value=32, max_value=1024, step=32)\n",
    "    pubmed_dropout2_hp_units = hp.Float('pubmed_dropout_2', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    struct_dense1_hp_units = hp.Int('struct_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    struct_dense2_hp_units = hp.Int('struct_dense_2', min_value=32, max_value=1024, step=32)\n",
    "    struct_dropout1_hp_units = hp.Float('struct_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "    \n",
    "    combo_dense1_hp_units = hp.Int('combo_dense_1', min_value=32, max_value=1024, step=32)\n",
    "    combo_dense2_hp_units = hp.Int('combo_dense_2', min_value=32, max_value=1024, step=32)\n",
    "    combo_dropout1_hp_units = hp.Float('combo_dropout_1', min_value=0.0, max_value=0.9, step=0.1)\n",
    "\n",
    "    #padded_cui cui2vec embedding\n",
    "    input1 = tf.keras.Input(shape=(max_length,))\n",
    "    nl = tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), input_length = max_length, trainable=False)(input1)\n",
    "    nl = tf.keras.layers.Flatten()(nl)\n",
    "    nl = tf.keras.layers.Dense(units = cui2vec_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "    nl = tf.keras.layers.Dropout(rate = cui2vec_dropout1_hp_units)(nl)\n",
    "    nl = tf.keras.layers.Dense(units = cui2vec_dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "\n",
    "    #pubmed CNN\n",
    "    input2 = tf.keras.Input(shape=(width,))\n",
    "    nl2 = tf.keras.layers.Embedding(vocabulary_pubmed_size, pubmed_embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(pubmed_embedding_matrix), input_length = width, trainable=False)(input2)\n",
    "    nl2 = tf.keras.layers.Dense(pubmed_dense1_hp_units, activation='relu')(nl2) \n",
    "    nl2 = tf.keras.layers.Dropout(pubmed_dropout1_hp_units)(nl2) \n",
    "    kernels = [3, 5, 7, 10] \n",
    "    pooled = [] \n",
    "    for kernel_size in kernels: \n",
    "        mini_layer = tf.keras.layers.Conv1D(pubmed_convo_hp_units, kernel_size, activation='relu')(nl2) \n",
    "        mini_pooled = tf.keras.layers.MaxPooling1D(width - kernel_size + 1)(mini_layer) \n",
    "        pooled.append(mini_pooled) \n",
    "    nl2 = tf.keras.layers.Concatenate(axis=1)(pooled) \n",
    "    nl2 = tf.keras.layers.Flatten()(nl2) \n",
    "    nl2 = tf.keras.layers.Dropout(pubmed_dropout2_hp_units)(nl2) \n",
    "    nl2 = tf.keras.layers.Dense(pubmed_dense3_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl2) \n",
    "    \n",
    "    #structured\n",
    "    input3 = tf.keras.Input(shape=(structuredArray.shape[1],))\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input3)\n",
    "    sl = tf.keras.layers.Dropout(rate = struct_dropout1_hp_units)(sl)\n",
    "    sl = tf.keras.layers.Dense(units = struct_dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "\n",
    "    combo = tf.keras.layers.Concatenate()([nl, nl2, sl])\n",
    "    combo = tf.keras.layers.Dense(combo_dense1_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(combo) \n",
    "    combo = tf.keras.layers.Dropout(combo_dropout1_hp_units)(combo) \n",
    "    combo = tf.keras.layers.Dense(combo_dense2_hp_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(combo)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(nl)\n",
    "\n",
    "    model = tf.keras.Model(inputs = (input1, input2, input3), outputs = output)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e07557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hyperparameter_tuning/struct05_newModelH/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from hyperparameter_tuning/struct05_newModelH/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete.\n",
      "----------------------------------------------\n",
      "Best results:\n",
      "Cui2vec- first densely-connected layer: 384\n",
      "Cui2vec- dropout layer: 0.6000000000000001\n",
      "Cui2vec- second densely-connected layer: 288\n",
      "\n",
      "Pubmed- first densely-connected layer: 96\n",
      "Pubmed- dropout layer: 0.1\n",
      "Pubmed- convo size layer: 160\n",
      "Pubmed- third densely-connected layer: 608\n",
      "Pubmed- dropout layer 2: 0.8\n",
      "\n",
      "Struct- first densely-connected layer: 896\n",
      "Struct- dropout layer: 0.8\n",
      "Struct- second densely-connected layer: 896\n",
      "\n",
      "Combo- densely-connected layer: 288\n",
      "Combo- densely-connected layer 2: 864\n",
      "Combo- dropout: 0.30000000000000004\n",
      "\n",
      "Optimal learning rate: 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=80,\n",
    "                     directory='hyperparameter_tuning',\n",
    "#                      project_name='lowva')\n",
    "                     project_name='struct05_newModelH');\n",
    "#                      overwrite=True);\n",
    "\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1),\n",
    "]\n",
    "\n",
    "tuner.search(train_dataset, epochs=80, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "----------------------------------------------\n",
    "Best results:\n",
    "Cui2vec- first densely-connected layer: {best_hps.get('cui2vec_dense_1')}\n",
    "Cui2vec- dropout layer: {best_hps.get('cui2vec_dropout_1')}\n",
    "Cui2vec- second densely-connected layer: {best_hps.get('cui2vec_dense_2')}\n",
    "\n",
    "Pubmed- first densely-connected layer: {best_hps.get('pubmed_dense_1')}\n",
    "Pubmed- dropout layer: {best_hps.get('pubmed_dropout_1')}\n",
    "Pubmed- convo size layer: {best_hps.get('pubmed_convo_size')}\n",
    "Pubmed- third densely-connected layer: {best_hps.get('pubmed_dense_3')}\n",
    "Pubmed- dropout layer 2: {best_hps.get('pubmed_dropout_2')}\n",
    "\n",
    "Struct- first densely-connected layer: {best_hps.get('struct_dense_1')}\n",
    "Struct- dropout layer: {best_hps.get('struct_dropout_1')}\n",
    "Struct- second densely-connected layer: {best_hps.get('struct_dense_2')}\n",
    "\n",
    "Combo- densely-connected layer: {best_hps.get('combo_dense_1')}\n",
    "Combo- densely-connected layer 2: {best_hps.get('combo_dense_2')}\n",
    "Combo- dropout: {best_hps.get('combo_dropout_1')}\n",
    "\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e982ea01",
   "metadata": {},
   "source": [
    "Best results:\\\n",
    "Cui2vec- first densely-connected layer: 384\\\n",
    "Cui2vec- dropout layer: 0.6000000000000001\\\n",
    "Cui2vec- second densely-connected layer: 288\\\n",
    "                \n",
    "Pubmed- first densely-connected layer: 96\\\n",
    "Pubmed- dropout layer: 0.1\\\n",
    "Pubmed- convo size layer: 160\\\n",
    "Pubmed- third densely-connected layer: 608\\\n",
    "Pubmed- dropout layer 2: 0.8\\\n",
    "\n",
    "Struct- first densely-connected layer: 896\\\n",
    "Struct- dropout layer: 0.8\\\n",
    "Struct- second densely-connected layer: 896\\\n",
    "\n",
    "Combo- densely-connected layer: 288\\\n",
    "Combo- densely-connected layer 2: 864\\\n",
    "Combo- dropout: 0.30000000000000004\\\n",
    "\n",
    "Optimal learning rate: 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d7766d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_input = tf.data.Dataset.from_tensor_slices(structuredArray)\n",
    "#total_input = tf.data.Dataset.from_tensor_slices(tokenArray)\n",
    "total_input = tf.data.Dataset.from_tensor_slices((padded_cui, structuredArray))\n",
    "total_output = tf.data.Dataset.from_tensor_slices(outputArray)\n",
    "total_dataset = tf.data.Dataset.zip((total_input, total_output))\n",
    "train_dataset = total_dataset.skip(600).shuffle(1000).batch(15)\n",
    "validation_dataset = total_dataset.skip(300).take(300).batch(15)\n",
    "test_dataset = total_dataset.take(300).batch(15)\n",
    "max_length = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "241fd803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 2000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 2000, 500)    7867000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2000, 512)    256512      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2000, 512)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1998, 256)    393472      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1996, 256)    655616      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1994, 256)    917760      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1991, 256)    1310976     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 256)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 256)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 256)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 256)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 256)       0           max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 556)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         1049600     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           35648       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           65600       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           4160        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           dense_12[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           8256        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            65          dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,564,665\n",
      "Trainable params: 4,697,665\n",
      "Non-trainable params: 7,867,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_2: expected shape=(None, 2000), found shape=(None, 4000)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15939/1632299622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m ]\n\u001b[1;32m     49\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/envs/haiwen/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_2: expected shape=(None, 2000), found shape=(None, 4000)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.Input(shape=(max_length,))\n",
    "nl = tf.keras.layers.Embedding(vocabulary_size, embedding_dimension, embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix), input_length = max_length, trainable=False)(input1)\n",
    "nl = tf.keras.layers.Dense(512, activation='relu')(nl)\n",
    "nl = tf.keras.layers.Dropout(0.50)(nl)\n",
    "kernels = [3, 5, 7, 10]\n",
    "pooled = []\n",
    "for kernel_size in kernels:\n",
    "    mini_layer = tf.keras.layers.Conv1D(256, kernel_size, activation='relu')(nl)\n",
    "    mini_pooled = tf.keras.layers.MaxPooling1D(max_length - kernel_size + 1)(mini_layer)\n",
    "    pooled.append(mini_pooled)\n",
    "nl = tf.keras.layers.Concatenate(axis=1)(pooled)\n",
    "nl = tf.keras.layers.Flatten()(nl)\n",
    "nl = tf.keras.layers.Dropout(0.50)(nl)\n",
    "nl = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "nl = tf.keras.layers.Dropout(0.5)(nl)\n",
    "nl = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(nl)\n",
    "\n",
    "input2 = tf.keras.Input(shape=(structuredArray.shape[1],))\n",
    "sl = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(input2)\n",
    "sl = tf.keras.layers.Dropout(0.50)(sl)\n",
    "sl = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(sl)\n",
    "\n",
    "combo = tf.keras.layers.Concatenate()([nl, sl])\n",
    "combo = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2())(combo)\n",
    "nl = combo\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(nl)\n",
    "\n",
    "#model = tf.keras.Model(inputs = input1, outputs = output)\n",
    "#model = tf.keras.Model(inputs = input2, outputs = output)\n",
    "model = tf.keras.Model(inputs = (input1, input2), outputs = output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(name='tp'), \n",
    "    tf.keras.metrics.FalsePositives(name='fp'), \n",
    "    tf.keras.metrics.TrueNegatives(name='tn'), \n",
    "    tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "    tf.keras.metrics.Recall(name='sen'), \n",
    "    tf.keras.metrics.Precision(name='prc'), \n",
    "    tf.keras.metrics.AUC(name='auroc'), \n",
    "    tf.keras.metrics.BinaryAccuracy(name='acc')\n",
    "]\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(patience=4, verbose=1, restore_best_weights=True, min_delta=0.0001), \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=2, verbose=1)\n",
    "]\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=metrics)\n",
    "history = model.fit(train_dataset, epochs=80, validation_data=validation_dataset, verbose=1, callbacks=callbacks)\n",
    "model.evaluate(validation_dataset)\n",
    "y_pred = model.predict(validation_dataset)\n",
    "model.save_weights('struct05_lowva_weights-XXXX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa00da",
   "metadata": {},
   "source": [
    "loss: 0.6591 - tp: 62.0000 - fp: 39.0000 - tn: 160.0000 - fn: 39.0000 - sen: 0.6139 - prc: 0.6139 - auroc: 0.7664 - acc: 0.7400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9f935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_loss(history)\n",
    "plt_acc(history)\n",
    "plt_roc(validation_dataset, y_pred)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python [conda env:haiwen]",
   "language": "python",
   "name": "conda-env-haiwen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
